<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Publications</title>
	<meta content="Publications, wanglimin.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

ul { 
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

strong, b {
	font-weight:bold;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'wanglimin.github.io');
  ga('send', 'pageview');

</script>
<body>

<div style="clear: both;">
<div class="section">
  <h2>Technical Reports</h2>
  <div class="paper">
    <ul>
	<li>
	X. Peng, <strong>L. Wang</strong>, X. Wang, and Y. Qiao, Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice, in arXiv:1405.4506.
	</li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Journal Papers</h2>
  <div class="paper">
    <ul>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, MoFAP: A Multi-Level Representation for Action Recognition, submitted to International Journal of Computer Vision (<strong>IJCV</strong>).
		</li>
	  <li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, Latent Hierarchical Model of Temporal Structure for Complex Activity Classification, in IEEE Transactions on Image Processing (<strong>TIP</strong>), Vol. 23, No. 2, 2014.  [ <a href='papers/WangQT_TIP14.pdf'>Paper</a> ]  [ <a href='papers/WangQT_TIP14.bib'>BibTex</a> ]
		</li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>CVPR/ICCV/ECCV Papers</h2>
  <div class="paper">
    <ul>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors, in IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2015. [ <a href='papers/WangQT_CVPR15.pdf'>Paper</a> ]  [ <a href='papers/WangQT_CVPR15.bib'>BibTex</a> ] [ <a href='papers/WangQT_CVPR15_abstract.pdf'>Extended Abstract</a> ] [ <a href='papers/WangQT_CVPR15_Poster.pdf'>Poster<a> ] [ <a href = 'tdd/index.html'>Project Page</a> ] 
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, Video Action Detection with Relational Dynamic-Poselets, in European Conference on Computer Vision (<strong>ECCV</strong>), 2014. 
		[ <a href='papers/WangQT_ECCV14.pdf'>Paper</a> ]  [ <a href='papers/WangQT_ECCV14.bib'>BibTex</a> ] [ <a href='papers/WangQT_ECCV14_Poster.pdf'>Poster</a> ] [ <a href='papers/WangQT_ECCV14_Spotlight.wmv'>Spotlight</a> ] [ <a href='release_plot.rar'>Code</a> ]
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, Mining Motion Atoms and Phrases for Complex Action Recognition, in IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2013. 
		[ <a href='papers/WangQT_ICCV13.pdf'>Paper</a> ]  [ <a href='papers/WangQT_ICCV13.bib'>BibTex</a> ] [ <a href='papers/WangQT_ICCV13_Poster.pdf'>Poster</a> ] [ <a href='papers/WangQT_ICCV13_Spotlight.ppt'>Spotlight</a> ]
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and Xiaoou Tang, Motionlets: Mid-Level 3D Parts for Human Motion Recognition, in IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2013. 
		[ <a href='papers/WangQT_CVPR13.pdf'>Paper</a> ]  [ <a href='papers/WangQT_CVPR13.bib'>BibTex</a> ] [ <a href='papers/WangQT_CVPR13_Poster.pdf'>Poster</a> ] [ <a href='papers/WangQT_CVPR13_Spotlight.ppt'>Spotlight</a> ] [ <a href = 'motionlet/'>Project Page</a> ]
		</li>
		<li> 
		Z. Cai, <strong>L. Wang</strong>, X. Peng, and Y. Qiao, Multi-View Super Vector for Action Recognition, in IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2014. 
		[ <a href='papers/CaiWPQ_CVPR14.pdf'>Paper</a> ]  [ <a href='papers/CaiWPQ_CVPR14.bib'>BibTex</a> ] [ <a href='papers/CaiWPQ_CVPR14.mp4'>Video Spotlight</a> ] [ <a href='papers/CaiWPQ_CVPR14_oral.ppt'>Oral Presentation</a> ] [ <a href='papers/CaiWPQ_CVPR14_poster.ppt'>Poster</a> ] [ <a href='papers/CaiWPQ_CVPR14_Supplement.pdf'>Supplement</a> ] [ <a href='papers/CaiWPQ_CVPR14.zip'>Code</a> ]  
		</li>
		<li> 
		X. Peng, <strong>L. Wang</strong>, Y. Qiao, and Q. Peng, Boosting VLAD with Supervised Dictionary Learning and High-Order Statistics, in European Conference on Computer Vision (<strong>ECCV</strong>), 2014. 
		[ <a href='papers/PengWQP_ECCV14.pdf'>Paper</a> ] [ <a href='papers/PengWQP_ECCV14.bib'>BibTex</a> ] 
		</li>
	</ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Other Conference Papers</h2>
  <div class="paper">
    <ul>
		<li> 
		X. Peng, <strong>L. Wang</strong>, Y. Qiao, and Q. Peng, A Joint Evaluation of Dictionary Learning and Feature Encoding for Action Recognition, in International Conference on Pattern Recognition (<strong>ICPR</strong>), 2014. [ <a href='papers/PengWQP_ICPR14.pdf'>Paper</a> ] [ <a href='papers/PengWQP_ICPR14.bib'>BibTex</a> ] 
		</li>
		<li> 
		X. Wang, <strong>L. Wang</strong>, and Y. Qiao, A Comparative Study of Encoding, Pooling and Normalization Methods for Action Recognition, in Asian Conference on Computer Vision (<strong>ACCV</strong>), 2012. [ <a href='papers/WangWQ_ACCV12.pdf'>Paper</a> ] [ <a href='papers/WangWQ_ACCV12.bib'>BibTex</a> ] [ <a href='papers/WangWQ_ACCV12_Poster.pdf'>Poster</a> ] [ <a href='papers/WangWQ_ACCV12_Spotlight.ppt'>Spotlight</a> ]
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Wu, T. Lu, and K. Chen,  Multiclass Object Detection by Combining Local Appearances and Context, in ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2011. [ <a href='papers/WangWLC_MM11.pdf'>Paper</a> ] [ <a href='papers/WangWLC_MM11.bib'>BibTex</a> ]
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Wu, Z. Tian, Z. Sun, and T. Lu, A Novel Approach for Robust Surveillance Video Content Abstraction, in Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2010. [ <a href='papers/WangWTSL_PCM10.pdf'>Paper</a> ] [ <a href='papers/WangWTSL_PCM10.bib'>BibTex</a> ]
		</li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Notebook Papers</h2>
  <div class="paper">
    <ul>
		<li>
		<strong>L. Wang</strong>, Z. Wang, Y. Xiong, and Y. Qiao, CUHK&SIAT Submission for THUMOS15 Action Recognition Challenge, in <strong>THUMOS'15</strong> Action Recognition Challenge, 2015. [ <a href='contests/WangWXQ_THUMOS15.pdf'>Paper</a>  ]<br /> 
		</li>
		<li>
		<strong>L. Wang</strong>, Z. Wang, W. Du, and Y. Qiao, Object-Scene Convolutional Neural Networks for Event Recognition in Images, in ChaLearn Looking at People (<strong>LAP</strong>) Challenge, 2015. [ <a href='papers/WangWDQ_ChaLearnLAP15.pdf'>Paper</a>  ]  [ <a href='papers/WangWDQ_ChaLearnLAP15.bib'>BibTex</a> ] [ <a href='papers/WangWDQ_ChaLearnLAP15_slide.pdf'>Presentation</a> ] [ <a href = 'cultural_event/index.html'>Project Page</a> ] <alert>rank 1st place</alert><br /> 
		</li>
		<li>
		Z. Wang, <strong>L. Wang</strong>, W. Du, and Y. Qiao, Exploring Fisher Vector and Deep Networks for Action Spotting, in ChaLearn Looking at People (<strong>LAP</strong>) Challenge, 2015. [ <a href='contests/WangWDQ_LAP15.pdf'>Paper</a>  ]  [ <a href='contests/WangWDQ_LAP15.bib'>BibTex</a> ] [ <a href='contests/WangWDQ_LAP15_slide.pdf'>Presentation</a> ] <alert>rank 1st place</alert> <br /> 
		</li>
		<li> 
		<strong>L. Wang</strong>, Y. Qiao, and X. Tang, Action Recognition and Detection by Combining Motion and Appearance Features, in <strong>THUMOS'14</strong> Action Recognition Challenge, 2014. [ <a href='contests/WangQT_Thumos14.pdf'>Paper</a> ] [ <a href='contests/WangQT_Thumos14_slide.pptx'>Presentation</a> ] 
		</li>
		<li> 
		X. Peng, <strong>L. Wang</strong>, Z. Cai, and Y. Qiao, Action and Gesture Temporal Spotting with Super Vector Representation, in ChaLearn Looking at People (<strong>LAP</strong>) Challenge, 2014. [ <a href='contests/PengWCQ_LAP14.pdf'>Paper</a> ] [ <a href='contests/PengWCQ_LAP14_slide.pdf'>Presentation</a> ] <alert>rank 1st place</alert>
		</li>
		<li> 
		X. Peng, <strong>L. Wang</strong>, Z. Cai, and Y. Qiao, Hybrid Super Vector with Improved Dense Trajectories for Action Recognition, in <strong>THUMOS'13</strong> Action Recognition Challenge, 2013. [ <a href='contests/PengWCQ_Thumos13.pdf'>Paper</a> ]
		</li>
    </ul>
  </div>
</div>
</div>

</body>
</html>